---
title: "p8105_hw6_td2809"
author: "Chris Deng"
date: "2023-11-30"
output: github_document
---
```{r}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)
library(viridis)


# remove the frame and change legend to bottom
theme_set(theme_minimal() + theme(legend.position = "bottom"))  

# change continuous variables with "viridis" for color and fill 
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

# change discrete variables with "viridis" for color and fill 
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
# Problem 1
```{r}
homicide_df = read_csv("data/homicide-data.csv") |>
  janitor::clean_names() |>
  mutate(city_state = paste(city, state, sep = ", "),
         solved = as_factor(if_else(disposition %in% c("Closed without arrest", "Closed by arrest"), 1, 0)),
         victim_age = as.numeric(victim_age)) |>
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
         victim_race %in% c("White", "Black"))
```

```{r}
baltimore_df = homicide_df %>%
  filter(city_state == "Baltimore, MD")

baltimore_glm <- glm(solved ~ victim_age + victim_sex + victim_race, family = binomial, data = baltimore_df)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```
Now, run `glm` for each of the cities in the dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims.
```{r}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(solved ~ victim_age + victim_sex + victim_race, family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```
Create a plot that shows the estimated ORs and CIs for each city.
```{r}
ggplot(model_results, aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper), width = 0.25) +
  coord_flip() +  # flip the axes 
  xlab("City") +
  ylab("Odds Ratio") +
  ggtitle("Odds Ratios with CI for Solving Homicides ")
```

# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```
```{r}
# Define bootstraps function
bootstraps = function(df) {
  sample_frac(df, replace = TRUE)
}

n = 5000

# Generate bootstrap samples
boot_samples = 
  tibble(boot_number = 1:n) |> 
  mutate(
    strap_sample = map(boot_number, \(i) bootstraps(df = weather_df))
  )

# Generate the estimates of interest
bootstrap_results = 
  boot_samples |>
  mutate(
    models = map(strap_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results_tidy = map(models, broom::tidy),
    results_glance = map(models, broom::glance)
  ) |> 
  select(-strap_sample, -models) |> 
  unnest(results_tidy, results_glance) |> 
  select(boot_number, term, estimate, r.squared)

# Alternative approach to pivot and mutate the dataset
bootstrap_results_2 = 
  bootstrap_results |> 
  pivot_wider(names_from = term, values_from = estimate) |> 
  mutate(log_product = if_else(tmin * prcp <= 0, NA_real_, log(tmin * prcp)))

head(bootstrap_results_2)
```
```{r}
bootstrap_results_2 |>
  ggplot(aes(x = r.squared)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  labs(title = "Distribution of R-squared Estimates", x = "R-squared", y = "Frequency")

bootstrap_results_2 |>
  ggplot(aes(x = log_product)) +
  geom_histogram(bins = 30, fill = "darkred", color = "black") +
  labs(title = "Distribution of log(beta1 * beta2) Estimates", 
       x = "log(beta1 * beta2)", y = "Frequency")
```
From Fig.1 we observe that the distribution of $\hat{r}^{2}$ is approximates the normal distribution and is approximately symmetric about 0.91. 
Fig.2 displays the distribution of $log(\hat{\beta _{1}}\times\hat{\beta _{2}})$, which exhibits a left-skewed bell-shaped curve, peaking around -5.5.

```{r}
# Calculate 95% confidence intervals for r^2 and log_product estimates
ci_95 = 
  bootstrap_results_2 |>
  summarize(
    lower_ci = c(quantile(r.squared, 0.025, na.rm = TRUE),
                 quantile(log_product, 0.025, na.rm = TRUE)),
    upper_ci = c(quantile(r.squared, 0.975, na.rm = TRUE),
                 quantile(log_product, 0.975, na.rm = TRUE))
  ) |> 
  mutate(quantity_type = c("r_squared", "log_product")) |>  
  select(quantity_type, lower_ci, upper_ci) 

# Display the confidence intervals in a table format
ci_95 |> 
  knitr::kable(digits = 3)

```
 *  The 95% CI for $\hat{r}^2$ is (`r round(ci_95[1, 2], digits = 3)`, `r round(ci_95[1, 3], digits = 3)`)
 *  The 95% CI for $\log(\hat{\beta}_1 \times \hat{\beta}_2)$ is (`r round(ci_95[2, 2], digits = 3)`, `r round(ci_95[2, 3], digits = 3)`)

# Problem 3
Load and clean the data for regression analysis 
```{r}
#load and tidy the data
birthweight_df = 
  read_csv("data/birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) |>
  drop_na()
```
The birth weight of infants can be influenced by various factors related to the baby's physique, gestational age, health status, and the mother's physical condition and lifestyle. Therefore, I have selected a range of predictors to forecast birth weight. These include  `bhead`, `blength`, `gaweeks`, ` delwt`, `mheight`, `momage`, `ppwt`, `smoken`.
```{r}
birthweight_MLR = 
  birthweight_df |>
  lm(bwt ~ bhead + blength + gaweeks + delwt + mheight + momage  + ppwt + smoken, data = _)
summary(birthweight_MLR)

# plot of residuals against fitted values
birthweight_df |>
  add_predictions(birthweight_MLR) |>
  add_residuals(birthweight_MLR) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = ("Fitted Value"),y = ("Residuals"), title = "Residuals Against Fitted Values")
```
```{r}
# Creating training and testing data
cv_df = crossv_mc(birthweight_df, 100)

# Fit data to three models and compare RMSE
cv_df = cv_df |>
  mutate(
    my_mod = map(train, \(df) lm(bwt ~ bhead + blength + gaweeks + delwt + mheight + momage  + ppwt + smoken, data = df)),
    main_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_mod = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))
  ) |>
  mutate(
    rmse_my = map2_dbl(my_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_mod, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) |>
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin() +
  labs(title = "RMSE Values for Each Candidate Model",
       x = "Models", 
       y = "Root Mean Square Error")
```
The data suggests that my model demonstrates the lowest RMSE, implying a superior fit to the data compared to the other two models. Conversely, the model solely incorporating the main effects of birth length and gestational age as predictors of birth weight exhibits the highest RMSE. This may indicate its relatively inferior performance in accurately predicting birth weight.